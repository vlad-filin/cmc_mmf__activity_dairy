{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions\n",
    "____________________\n",
    "\n",
    "date 16.02.2018, paper on [arxiv](https://arxiv.org/pdf/1712.05884.pdf)\n",
    "\n",
    "It is recommended to check tacotron review first, since some concepts were explained there.\n",
    "_______________________\n",
    "## Overview\n",
    "\n",
    "Authors proposed modifying tacotron architecture and using generative neural network (say, wavenet) instead of Griffin-Lim algorithm for synthesis. **In this report only tacotron modification are covered**,  and generative part is not, since in github authors uses WaveGlow model for generating audio, and it is separate article. \n",
    "\n",
    "Model can be splitted into several parts:\n",
    "\n",
    "* Encoder;\n",
    "* Decoder with attention;\n",
    "* Post-Net;\n",
    "\n",
    "Model takes as input one hot encoded characters and outputs limited sequence of 80 band mel spectrograms (so length of generated text is limited, but this is not an issue since current hidden vectors could be used for next sentence generation, but most common way - to generate not so long sentences separately, ignoring dependencies between them). Model also outputs probability of stop token - indicator that model outputted all required mel spectrograms for speech generation.\n",
    "\n",
    "\n",
    "\n",
    "Overall architecture is shown below:\n",
    "<img src=\"images/TTSArchitecture.jpg\" width=\"700\">\n",
    "\n",
    "### Encoder\n",
    "Encoder takes as input sequence of learnable character embeddings (same as tacotron encoder does) and first perform convolutions on time axis preserving spatial dimension (same as CBHG convolutions in tacotron). After convolution is done working dimension (dimension for matrix multiplication in linear layers) is embedding dimension and convolutions outputs is passed through bidirectional LSTM (same as GRU in tacotron).\n",
    "### Decoder with attention\n",
    "Decoder takes as input previous generated frame and passes it through pre-net(two linear layers with relu and dropout). The encoder output is consumed by an attention network which summarizes the full encoded sequence as a fixed-length context vector for each decoder output step. Context vector for each time step is constructed as following (let $\\alpha_i$ be the alignment from previous step, $(h_1, \\dots, h_L)$ - encoder outputs, $s_{i}$ - attention rnn hidden vector (same as tacotron)):\n",
    "1. First, we extract $k$ vectors $f_{i,j} \\in \\mathbb{R}^{k}$ for\n",
    "every position $j$ of the previous alignment $\\alpha_{i-1}$  by convolving it\n",
    "with a matrix $F \\in \\mathbb{R}^{k \\times r}$:\n",
    "\\begin{align}\n",
    "    \\label{eq:conv_feats}\n",
    "    f_i = F * \\alpha_{i-1}.\n",
    "\\end{align}\n",
    "2. These additional vectors $f_{i,j}$ are then used by the scoring mechanism $e_{i,j}$:\n",
    "\\begin{align}\n",
    "    \\label{eq:hybrid_score}\n",
    "    e_{i,j} = w^\\top \\tanh(W s_{i} + V h_j + U f_{i,j} + b)\n",
    "\\end{align}\n",
    "3. \\begin{align}\n",
    "    \\alpha_{i,j} = \n",
    "        \\exp(e_{i,j}) \\left/\n",
    "        \\sum\\limits_{j=1}^L \\exp(e_{i,j}) \\right..\n",
    "\\end{align}    \n",
    "4.  Attention context on step i is calculated via:\n",
    "$$\n",
    "    g_i = \\sum\\limits_{j=1}^L \\alpha_{i,j} h_j \n",
    "$$\n",
    "\n",
    "**$ F, U, V,W, b, w$ are trainable parameters**\n",
    "After that $(g_i, s_i)$ are concatenated and passed through decoder RNN (2 layer LSTM). Its output transformed via two linear transformations, first is used for stop token prediction, latter - is used at not refined mel spectrogram at current step (refining is done in Post-Net).\n",
    "\n",
    "### Post-Net\n",
    "\n",
    "Small 1-d convolutional neural network with dropout (unusual for CNN to use dropout) and non-linearities preserving spatial domain, convolutions is done on time axis domain, using band axis as channel axis (same as postnet in tacotron). Post-net takes as input decoder outputs after all sequential steps (same as tacotron postnet).\n",
    "\n",
    "### Training\n",
    "\n",
    "During training groundtruth mel-spectrogram of previous frame used as input to decoder (for the first frame 0 spectrogram is used). L2 loss was used on mel spectrograms produced at each decoder timestep and postnet outputs. Binary cross entropy loss was used for stop token. \n",
    "\n",
    "### Testing\n",
    "\n",
    " During testing previous generated by decoder mel-spectrogram is used as input. Generation is done until probability of end token is below 0.5 or until max decoder step is reached (this is uncommon situation and must be the case only for very very very long sentences).\n",
    " \n",
    " \n",
    "### Experiments and pros and cons\n",
    " Experiments and pros and cons aren't covered in this review since they are highly depended on generative model, which is conditioned on generated by tacotron2 mel spectrograms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
